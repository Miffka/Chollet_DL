{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Themes of the chapter:\n",
    "\n",
    "* The Keras functional API\n",
    "* Using Keras callback\n",
    "* Working with the TensorBoard visualization tool\n",
    "* Important best practices for developing state-of-the-art models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras functional API\n",
    "\n",
    "The functional API allows multimodal inputs, multiple outputs or branched structures (i.e. acyclic graphs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to the functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Intro to the functional API '''\n",
    "\n",
    "# Main principle - use layers as functions\n",
    "\n",
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))\n",
    "dense = layers.Dense(32, activation='relu')\n",
    "output_tensor = dense(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Dense object at 0x1c20ef2160>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-db579f9e1949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbad_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     90\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    190\u001b[0m                                  \u001b[0;34m'the output of a TensorFlow `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                                  \u001b[0;34m'(thus holding past layer metadata). '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                                  'Found: ' + str(x))\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Dense object at 0x1c20ef2160>"
     ]
    }
   ],
   "source": [
    "''' In input tensor and output tensor are unrelated, you get Runtime error '''\n",
    "\n",
    "unrelated_input = Input(shape=(32,1))\n",
    "bad_model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-input models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Implementation of a two-input question-answer model '''\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import Input, layers\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "# Branch 1\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input) # There was errata\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# Branch 2\n",
    "question_input = Input(shape=(None,),\n",
    "                       dtype='int32',\n",
    "                       name='question')\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input) # And there too\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# Concatenation & following\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question],\n",
    "                                  axis=-1)\n",
    "answer = layers.Dense(answer_vocabulary_size,\n",
    "                      activation='softmax')(concatenated)\n",
    "\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 32)           12416       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 16)           3136        embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 48)           0           lstm_5[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 500)          24500       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 0.0000e+00 - acc: 0.0040\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.0000e+00 - acc: 0.0040\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c21a147f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Feeding data to a multi-input model '''\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocabulary_size,\n",
    "                         size=(num_samples, max_length))\n",
    "answers = np.random.randint(0, 1, size=(num_samples, answer_vocabulary_size))\n",
    "\n",
    "# Fit using list of inputs\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# OR\n",
    "\n",
    "# Fit using a dictionary of inputs\n",
    "#model.fit({'text': text, 'question': question}, answers,\n",
    "#          epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "posts (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    12800000    posts[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 128)    163968      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, None, 128)    0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 256)    164096      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, None, 256)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 256)    327936      max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 256)          0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "age (Dense)                     (None, 1)            129         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "income (Dense)                  (None, 10)           1290        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gender (Dense)                  (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,490,444\n",
      "Trainable params: 13,490,444\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "''' Implementation of a three-output model '''\n",
    "\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups,\n",
    "                                 activation='softmax',\n",
    "                                 name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, \n",
    "              [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Computation options for multi-output model '''\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse', \n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very imbalanced loss contributions will cause the model representations be optimized preferentially for the task with the largest individual loss. You can assign different levels of importance to the loss values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Multi-output model: loss weightning '''\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "              loss_weights=[0.25, 1., 19.])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse',\n",
    "                    'income': 'categorical_crossentropy',\n",
    "                    'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25,\n",
    "                            'income': 1.,\n",
    "                            'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46379  1471 16278 39685  7927 22344 18419 20028 17623 16181 14711 17321\n",
      "  2136 31182  7109  3442  2877 42261 21870 23838  6092 44632 14292 48967\n",
      " 49901 17699 36182 45835 19542 47721 15665 30554 36761 31226 15835 17588\n",
      "  5989  8599 16744 30861 24026 43107  8837 16317 26366 39801   542  2647\n",
      "  2253 32684 32215 25042 47415 17775 21028 22715 47055 25890 22629 25135\n",
      " 26575 45971   256 48074  7911 46732 26745  5018 18651 28165 27068 48507\n",
      " 14102 38835 24332 23386 10383 48908 26603  3681 46439 35138 26643 21904\n",
      " 47342 17126 33012 18668 35007 42619  3098 42895 24596 20972 18389 26850\n",
      " 37025 23240 18434 49985 49939  3631 18199 11381 15486  7778 14937  2139\n",
      " 40494 14971 48050 28024 36686 26201 27068 17309 44618  8383 29208  5311\n",
      " 36283 20892 33411 17130 33797 36663 19365 33739 33336  6138 17180 39718\n",
      " 49582 20604  4388  6709   322 14769 48479 38615 24470 33462  5872 49187\n",
      " 11515 29624 33073 36089 15120  7680 27418 21819 21513 13147 38369  6632\n",
      " 28133  8478 38450 35576 26492  1632 34879 32208 18969 13216   603 22532\n",
      " 34181  5547 13776 24708 35088 14868 13789 21354 13000  2063 30109  2410\n",
      "  6534 35200 13039 10116 16734 13758  6757 32841 13798 13448  2925 25963\n",
      " 49583  4442 23677 18336  1630  6950 41164  8545 41173 31028 30738 23113\n",
      " 39038 19182 39295  7524 31405 48838 10576 31996 34587 49048 22109 46970\n",
      " 35964 27729 17948 24390 47624 42075 49654 38226 36208  5548 19608 29089\n",
      " 34157 35945 16506 24999 28338 19089 46195 29817 20932  7390  1187 22765\n",
      " 41789   133 26108 12693 32963 49820 43047 23404  1139 49738 13056   180\n",
      "  8878  5743  6502 45244 31780 13967 15831   931 37321 44168  5048 16254\n",
      " 32147  6970 46383 21636  8054 44812 11207 24144 15514 35697  4475  5136\n",
      "  6311 26225 26908 40371 43003 38219 21504 16601 22250 32398 40802 21379\n",
      " 11282  4972  2095 17417 33916 48331 24329  3201 22227 43754  8701 16085\n",
      "  1483 25556 14660  8676 29882 14737 40496 36128 31629 30747  1352 38417\n",
      " 35170 30262 31402 21235  8148  6907 35248  2378  3686 42592 38653 18637\n",
      " 22512 46174 28087 21284 21418  1084 42294  4277 12688 20830 12266 28246\n",
      "  5232 39731 13042 30448 39895  7395  5042 35592 48250 30211 48256 17928\n",
      " 36883 43389 16640  7376 33446 45902 10816 26930  8264 10915 49532  4246\n",
      " 34585 39597 14821 30574 11441  2794 39895  4718 34970  4717 22494 26109\n",
      " 42410 38042 13734 10394 38100 35188 23798 30221 36659 18228 27938 41630\n",
      " 49145 33549 33563 27288 41091 13482 49717 38495 11240 11961 38571 16307\n",
      "   530 31254 28164  2551] 52 [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.] 0\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 365.7882 - age_loss: 1443.0209 - income_loss: 4.1662 - gender_loss: 0.0867\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 155.3374 - age_loss: 606.3646 - income_loss: 3.7434 - gender_loss: 2.7879e-04\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 87.6134 - age_loss: 339.3185 - income_loss: 2.7781 - gender_loss: 5.7079e-04\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 54.1717 - age_loss: 207.5104 - income_loss: 2.2872 - gender_loss: 6.8437e-04\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 45.6139 - age_loss: 173.4228 - income_loss: 2.2532 - gender_loss: 5.0525e-04\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 38.4612 - age_loss: 144.6834 - income_loss: 2.2880 - gender_loss: 2.3414e-04\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 45.4015 - age_loss: 172.4499 - income_loss: 2.2869 - gender_loss: 2.1211e-04\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 42.9983 - age_loss: 162.9333 - income_loss: 2.2640 - gender_loss: 9.7333e-05\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 32.2150 - age_loss: 119.6795 - income_loss: 2.2943 - gender_loss: 8.4469e-05\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 42.3874 - age_loss: 160.5386 - income_loss: 2.2524 - gender_loss: 3.6644e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1f8c1748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Feeding data do the multi-output model '''\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 400\n",
    "\n",
    "posts = np.random.randint(1, vocabulary_size,\n",
    "                          size=(num_samples, max_length))\n",
    "\n",
    "age_targets = np.random.randint(10, 110, \n",
    "                                size=(num_samples,))\n",
    "income_targets = np.random.randint(1, num_income_groups,\n",
    "                                   size=(num_samples,))\n",
    "income_targets = to_categorical(income_targets)\n",
    "gender_targets = np.random.randint(0, 1,\n",
    "                                   size=(num_samples,))\n",
    "\n",
    "print(posts[0], age_targets[0], income_targets[0], gender_targets[0])\n",
    "\n",
    "model.fit(posts, [age_targets, income_targets, gender_targets],\n",
    "          epochs=10, batch_size=64)\n",
    "\n",
    "#model.fit(posts, {'age': age_targets,\n",
    "#                  'income': income_targets,\n",
    "#                  'gender': gender_targets},\n",
    "#          epochs=10,\n",
    "#          batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed acyclic graph of layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Inception modules*\n",
    "\n",
    "Three to four branches starting with (1 \\* 1) convolution layers, followed by (3 \\* 3) layers and (5 \\* 5) layers on some branches.\n",
    "\n",
    "##### The purpose of 1 \\* 1 convolutions\n",
    "\n",
    "Information from channels mixes together, but not in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 256, 256, 128), (None, 255, 255, 128), (None, 253, 253, 128), (None, 254, 254, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f4c2c816bdb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mbranch_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbranch_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch_d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 256, 256, 128), (None, 255, 255, 128), (None, 253, 253, 128), (None, 254, 254, 128)]"
     ]
    }
   ],
   "source": [
    "''' Implement one block of Inception '''\n",
    "\n",
    "from keras import layers, Input\n",
    "\n",
    "x = Input(shape=(512,512,3))\n",
    "\n",
    "branch_a = layers.Conv2D(128, 1,\n",
    "                         activation='relu', strides=2)(x)\n",
    "\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Residual connections*\n",
    "\n",
    "Is added to any model with more than 10 layers. Consists of making the output of an earlier layer available as input to a later layer, creating a shortcut in a sequential network. The earlier output is summed with the later activation, which assumes that both activation are the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Operands could not be broadcast together with shapes (256, 256, 128) (256, 256, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c15ff9d20765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(inputs, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m     \"\"\"\n\u001b[0;32m--> 547\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mAdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    432\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_elemwise_op_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;31m# If the inputs have different ranks, we have to reshape them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# to make them broadcastable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Public/Conda/anaconda3/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36m_compute_elemwise_op_output_shape\u001b[0;34m(self, shape1, shape2)\u001b[0m\n\u001b[1;32m     59\u001b[0m                     raise ValueError('Operands could not be broadcast '\n\u001b[1;32m     60\u001b[0m                                      \u001b[0;34m'together with shapes '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                      str(shape1) + ' ' + str(shape2))\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0moutput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Operands could not be broadcast together with shapes (256, 256, 128) (256, 256, 3)"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "\n",
    "x = Input(shape=(256, 256, 3))\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer weight sharing\n",
    "\n",
    "For example, model attempts to assess the semantic similarity between two sentences. The model has two inputs (the two sentences to compare) and outputs a score between 0 and 1, where 0 means unrelated sentences and 1 means sentences that are either identical or reformulations of each other.\n",
    "\n",
    "The two input sentences are interchangeable, because semantic similarity is a symmetrical relationship: the similarity of A to B is identical to the similarity of B to A. It wouldn't make sense to learn two independent models for processing each input sentence. We use *Siamese LSTM* (or *shared LSTM*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)\n",
    "\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model([left_input, right_input], predictions)\n",
    "# The weights of shared layer are updated based on both inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models as layers\n",
    "\n",
    "We can stack different models as layers - as we did with the pretrained network.\n",
    "\n",
    "Example: vision model that uses a dual camera as its input, i.e. two parallel cameras, a few centimeters apart. Such a model can perceive depth, which can be useful in many application. You shouldn't need two independent models to extract visual features from the left camera and the right camera before merging the two feeds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate(\n",
    "    [left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up on functional API\n",
    "\n",
    "* Feel free to use functional API.\n",
    "* You can build a model with several inputs, several outputs and complex internal topology.\n",
    "* You can reuse weights of a layers or model across different processing branches, by calling the same layer or model instance several times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting and monitoring deep-learning models using Keras callbacks and TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using callbacks to act on a model during training\n",
    "\n",
    "* *Model checkpointing* - Saving the current weights of the model at different points during training.\n",
    "* *Early stopping* - interrupting training when the validation loss is no longer improving.\n",
    "* *Dynamically adjusting the value of certain parameter during training* - such as the learning rate or optimizer.\n",
    "* *Logging training and validation metrics during training* - the Keras progress bar.\n",
    "\n",
    "**keras.callbacks**:\n",
    "\n",
    "- keras.callbacks.ModelCheckpoint\n",
    "- keras.callbacks.EarlyStopping\n",
    "- keras.callbacks.LearningRateScheduler\n",
    "- keras.callbacks.ReduceLROnPlateau\n",
    "- keras.callbacks.CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ModelCheckpoint and EarlyStopping callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "callbacks_list = [ \n",
    "        keras.callbacks.EarlyStopping(monitor='acc', # monitors if the validation accuracy\n",
    "                                      patience=1), # stops improving for two epochs\n",
    "        keras.callbacks.ModelCheckpoint(filepath='my_model.h5', # saves the model\n",
    "                                        monitor='val_loss', # if validation loss\n",
    "                                        save_best_only=True) # is the best\n",
    "]\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val)) # obligatory because of callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The ReduceLROnPlateau callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', # reduces LR based on val_loss\n",
    "                                          factor=0.1, # divides LR by 10\n",
    "                                          patience=10) # waits for the moment 10 epochs\n",
    "]\n",
    "\n",
    "model.fit(x, y,\n",
    "          epochs=10,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing custom callback\n",
    "\n",
    "You rewrite method for a new class(keras.callbacks.Callback). The methods are:\n",
    "\n",
    "- on_epoch_begin\n",
    "- on_epoch_end\n",
    "- on_batch_begin\n",
    "- on_batch_end\n",
    "- on_train_begin\n",
    "- on_train_end\n",
    "\n",
    "Callbacks have access to:\n",
    "\n",
    "* logs (training/validation metrics of batch, epoch, run)\n",
    "* self.model - model instance\n",
    "* self.validation_data - validation data passed to model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Writing custom callback that  '''\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbacks.Callback):\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input,\n",
    "                                                    layer_outputs)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError('Requires validation_data.')\n",
    "        validation_sample = self.validation_data[0][0:1]\n",
    "        activations = self.activations_model.predict(validation_sample)\n",
    "        with open('activation_at_epoch' + str(epoch) + '.npz', 'w') as f:\n",
    "            np.savez(f, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to TensorBoard\n",
    "\n",
    "Works only with TensorFlow backend.\n",
    "\n",
    "Browser-based visualization tool that helps in:\n",
    "\n",
    "* Visually monitoring metrics during training\n",
    "* Visualizing model architecture\n",
    "* Visualizing histograms of activations and gradients\n",
    "* Exploring embeddings in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Text-classification model to use with TensorBoard '''\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Embedding(max_features, 128,\n",
    "                           input_length=max_len,\n",
    "                           name='embed'))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.MaxPooling1D(5))\n",
    "model.add(layers.Conv1D(32, 7, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "# make dir for logs (shell: mkdir my_log_dir)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(\n",
    "        log_dir='my_log_dir',\n",
    "        histogram_freq=1,\n",
    "        embedding_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# shell: tensorboard --logdir=my_log_dir\n",
    "# browse http://localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' How to plot model '''\n",
    "\n",
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State-of-the-art tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced architecture patterns\n",
    "\n",
    "* Residual connections\n",
    "* Batch normalization\n",
    "* Depthwise separable convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Batch normalization*\n",
    "\n",
    "Layer **BatchNormalization** can adaptively normalize data even as the mean and variance change over time.\n",
    "\n",
    "Internal maintaining an exponential moving average of the batch-wise mean and variance of data seen during training. Helps in very deep models.\n",
    "\n",
    "The BatchNormalization is typically used after a convolutional or densely connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "\n",
    "dense_model.add(layers.Dense(32, activation='relu'))\n",
    "dense_model.add(layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Depthwise separable convolution*\n",
    "\n",
    "Split channels and train convolutional layers for each channel independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3,\n",
    "                                 activation='relu',\n",
    "                                 input_shape=(height, width, channels,)))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "Process typically looks like this:\n",
    "\n",
    "1) Choose a set of hyperparameters (automatically).\n",
    "\n",
    "2) Build the corresponding model.\n",
    "\n",
    "3) Fit it to your training data, and measure the final performance on the validation data.\n",
    "\n",
    "4) Choose the next set of hyperparameters to try (automatically).\n",
    "\n",
    "5) Repeat.\n",
    "\n",
    "6) Eventually, measure performance on test data.\n",
    "\n",
    "Two techniques: Grid Search and Random Search are most useful.\n",
    "\n",
    "One more - Hyperopt (https://github.com/hyperopt/hyperopt). One more - Hyperas (https://github.com/maxpumperla/hyperas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model ensembling\n",
    "\n",
    "Different good models trained independently are likely to be good *for different reasons*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_a = model_a.predict(x_val)\n",
    "preds_b = model_b.predict(x_val)\n",
    "preds_c = model_c.predict(x_val)\n",
    "preds_d = model_d.predict(x_val)\n",
    "\n",
    "final_preds = 0.25 * (preds_a + preds_b + preds_c + preds_d)\n",
    "\n",
    "# OR\n",
    "\n",
    "final_preds = 0.5 * preds_a + 0.25 * preds_b + 0.1 * preds_c + 0.15 * preds_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models should be as good as possible and as different as possible - trees and deep networks, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping up\n",
    "\n",
    "* When building high-performing deep convnets, use residual connections, batch normalization and depthwise separable convolutions.\n",
    "* Building deep networks requires making many small hyperparameter and architecture choices. Rather than basing these choices on intuition or random chanse, it's better to systematically search hyperparameter space to find optimal choices.\n",
    "* Large ensembles of different models are cool, use them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
